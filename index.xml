<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>A Journey Towards Deeper Understanding</title>
    <link>http://aineedattention.blog/</link>
    <description>Recent content on A Journey Towards Deeper Understanding</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Mar 2024 04:42:21 +0530</lastBuildDate>
    <atom:link href="http://aineedattention.blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Need for Speed: Accelerating Python with sprinkles of C&#43;&#43;</title>
      <link>http://aineedattention.blog/docs/whypython/</link>
      <pubDate>Mon, 11 Mar 2024 04:42:21 +0530</pubDate>
      <guid>http://aineedattention.blog/docs/whypython/</guid>
      <description>Get out of the python For building performant system python is not really a good language. There are many lacking factors in python which makes it difficult to use for production level systems.
Drawbacks of python Python is not a compiled language. Python is not a statically typed language. Python is not very parallelisable cause of GIL (Global Interpreter Lock). Pros of python Python is very easy to learn. Python is good for prototyping and small scale projects.</description>
    </item>
    <item>
      <title>Need For Speed</title>
      <link>http://aineedattention.blog/docs/speed/</link>
      <pubDate>Sat, 17 Feb 2024 06:32:09 +0530</pubDate>
      <guid>http://aineedattention.blog/docs/speed/</guid>
      <description>The Need for Speed: Unveiling the Drive Behind Large Language Models Large Language Models (LLMs) have taken the world by storm, generating human-quality text, translating languages with unprecedented accuracy, and even composing creative pieces like poems and code. But beneath this impressive facade lies a constant struggle: the need for speed. Just like a high-performance car, LLMs require a complex engine and meticulously tuned components to function at their best. In this blog post, we&amp;rsquo;ll delve into the factors that influence the speed of these language marvels and explore the challenges and solutions that push them to their limits.</description>
    </item>
    <item>
      <title>Introduction</title>
      <link>http://aineedattention.blog/docs/test/</link>
      <pubDate>Sat, 17 Feb 2024 04:25:03 +0530</pubDate>
      <guid>http://aineedattention.blog/docs/test/</guid>
      <description>Welcome to AINeedAttention.blog I&amp;rsquo;m thrilled you&amp;rsquo;re here, because we share a common interest: Artificial Intelligence. I&amp;rsquo;m particularly invested in delving deep into AI to uncover the oft-overlooked aspects of what makes it work â€“ the things that need our attention, focus, and deeper understanding.
My Objective The purpose of this blog, as the name suggests, is to shed light on the low-level mechanisms of AI. I firmly believe that understanding these mechanisms is crucial to appreciating the full potential of AI technologies while optimizing their capabilities.</description>
    </item>
  </channel>
</rss>
